{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "firstUnitDisband_target4_randact.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVgbk7pD5gFkoYKll354Ku"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFf9FEjyd9MG",
        "colab_type": "text"
      },
      "source": [
        "## **First Unit Disband:** Target Fortress (Node 4) vs Random Action\n",
        "\n",
        "#### Predict winner of game based the following features:\n",
        "* Player 0 score (target Node 4 \"Fortress\")\n",
        "* Player 1 score (Random Action)\n",
        "* Win Type\n",
        "* Turn Unit Loss Occurred\n",
        "* Unit Lost Type\n",
        "* First player to disband a tank\n",
        "\n",
        "####Classifiers used:\n",
        "* Logistic Regression\n",
        "* KNN\n",
        "* Random Forest\n",
        "* SVM\n",
        "* XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N18AwC7p8BGp",
        "colab": {}
      },
      "source": [
        "# import Logistic Regression, KNN, Random forest, and SVM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# import xgboost (trying another classifier)\n",
        "import xgboost as xgb\n",
        "\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61iNHAcpdqG5",
        "colab_type": "code",
        "outputId": "09db6212-959a-46a0-80f2-28026bdab5ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/shaunhyp57/LMCO-Everglades-Robot-Behavior-Analytics/master/analytics/ml_models/First%20Unit%20Disband/datasets/firstUnitLost_target4_randact.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numberOfTurns</th>\n",
              "      <th>winType</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>unitLossTurn</th>\n",
              "      <th>unitLostPlayer</th>\n",
              "      <th>unitLostType</th>\n",
              "      <th>combinedStat</th>\n",
              "      <th>winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1354</td>\n",
              "      <td>1443</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1468</td>\n",
              "      <td>2278</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1341</td>\n",
              "      <td>1124</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>781</td>\n",
              "      <td>1989</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>557</td>\n",
              "      <td>1544</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   numberOfTurns  winType  player_0  ...  unitLostType  combinedStat  winner\n",
              "0          150.0        1      1354  ...             3             3       1\n",
              "1          150.0        1      1468  ...             1             1       1\n",
              "2          150.0        1      1341  ...             1             1       0\n",
              "3          150.0        1       781  ...             1             1       1\n",
              "4          150.0        1       557  ...             3             3       1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br1tOX4mrPGO",
        "colab_type": "code",
        "outputId": "bb43e8c0-5e0d-4d53-dec5-32ccf9d728d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "del data['combinedStat']\n",
        "\n",
        "# Used to categorize the winner of the game based on the score of the player column\n",
        "players={'player_0':0, 'player_1':1}\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numberOfTurns</th>\n",
              "      <th>winType</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>unitLossTurn</th>\n",
              "      <th>unitLostPlayer</th>\n",
              "      <th>unitLostType</th>\n",
              "      <th>winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1354</td>\n",
              "      <td>1443</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1468</td>\n",
              "      <td>2278</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1341</td>\n",
              "      <td>1124</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>781</td>\n",
              "      <td>1989</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150.0</td>\n",
              "      <td>1</td>\n",
              "      <td>557</td>\n",
              "      <td>1544</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   numberOfTurns  winType  player_0  ...  unitLostPlayer  unitLostType  winner\n",
              "0          150.0        1      1354  ...               1             3       1\n",
              "1          150.0        1      1468  ...               1             1       1\n",
              "2          150.0        1      1341  ...               1             1       0\n",
              "3          150.0        1       781  ...               1             1       1\n",
              "4          150.0        1       557  ...               1             3       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT58t63rgzTJ",
        "colab_type": "code",
        "outputId": "bb065ef2-3816-4c17-b9a5-c0ed458a01b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Total number of matches\n",
        "n_matches = data.shape[0]\n",
        "\n",
        "# Calculate number of features. '-1' because one is saved as target\n",
        "n_features = data.shape[1] - 1\n",
        "\n",
        "# Calculate matches won by Player 0\n",
        "n_player0wins = len(data[data.winner == 0])\n",
        "\n",
        "# Calculate win rate for Player 0\n",
        "win_rate = (float(n_player0wins) / (n_matches)) * 100\n",
        "\n",
        "# Print the results\n",
        "print(\"Total number of matches: {}\".format(n_matches))\n",
        "print(\"Number of features: {}\".format(n_features))\n",
        "print(\"Number of matches won by Player 0: {}\".format(n_player0wins))\n",
        "print(\"Win rate of Player 0: {:.2f}%\".format(win_rate))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of matches: 1000\n",
            "Number of features: 7\n",
            "Number of matches won by Player 0: 120\n",
            "Win rate of Player 0: 12.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EgIyYDJKDMM",
        "colab_type": "code",
        "outputId": "77c621f8-c611-4cdd-ce57-eb3d46b6ec06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "feature_cols = ['numberOfTurns', 'winType', 'player_0','player_1','unitLossTurn','unitLostPlayer','unitLostType']\n",
        "X = data[feature_cols]\n",
        "y = data['winner']\n",
        "\n",
        "# Standardising the data.\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "X = pd.DataFrame(scale(X), columns=feature_cols, index=data.index)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numberOfTurns</th>\n",
              "      <th>winType</th>\n",
              "      <th>player_0</th>\n",
              "      <th>player_1</th>\n",
              "      <th>unitLossTurn</th>\n",
              "      <th>unitLostPlayer</th>\n",
              "      <th>unitLostType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.088485</td>\n",
              "      <td>-0.100504</td>\n",
              "      <td>0.935204</td>\n",
              "      <td>-0.891782</td>\n",
              "      <td>0.827458</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>2.202128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.088485</td>\n",
              "      <td>-0.100504</td>\n",
              "      <td>1.209860</td>\n",
              "      <td>0.626939</td>\n",
              "      <td>0.178217</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>-0.504852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.088485</td>\n",
              "      <td>-0.100504</td>\n",
              "      <td>0.903883</td>\n",
              "      <td>-1.471988</td>\n",
              "      <td>-1.012059</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>-0.504852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.088485</td>\n",
              "      <td>-0.100504</td>\n",
              "      <td>-0.445308</td>\n",
              "      <td>0.101298</td>\n",
              "      <td>-0.687438</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>-0.504852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.088485</td>\n",
              "      <td>-0.100504</td>\n",
              "      <td>-0.984984</td>\n",
              "      <td>-0.708080</td>\n",
              "      <td>-0.579231</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>2.202128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   numberOfTurns   winType  ...  unitLostPlayer  unitLostType\n",
              "0       0.088485 -0.100504  ...        0.501562      2.202128\n",
              "1       0.088485 -0.100504  ...        0.501562     -0.504852\n",
              "2       0.088485 -0.100504  ...        0.501562     -0.504852\n",
              "3       0.088485 -0.100504  ...        0.501562     -0.504852\n",
              "4       0.088485 -0.100504  ...        0.501562      2.202128\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogxk6RWGdyQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=4, stratify = y)\n",
        "\n",
        "#svc_model = SVC(kernel='linear')\n",
        "#svc_model.fit(X_train, y_train)\n",
        "#y_pred = svc_model.predict(X_test)\n",
        "#print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw6CqdumLdfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for measuring training time\n",
        "from time import time \n",
        "#for measuring accuracy. Considers both precision and recall to compute score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_classifier(clf, X_train, y_train):\n",
        "    ''' Fits a classifier to the training data. '''\n",
        "    \n",
        "    # Start the clock, train the classifier, then stop the clock\n",
        "    start = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    end = time()\n",
        "    \n",
        "    # Print the results\n",
        "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
        "    \n",
        "    \n",
        "def predict_labels(clf, features, target):\n",
        "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
        "    \n",
        "    # Start the clock, make predictions, then stop the clock\n",
        "    start = time()\n",
        "    y_pred = clf.predict(features)\n",
        "    \n",
        "    end = time()\n",
        "    # Print and return results\n",
        "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
        "    \n",
        "    return f1_score(target, y_pred, pos_label=0), sum(target == y_pred) / float(len(y_pred))\n",
        "\n",
        "\n",
        "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
        "    ''' Train and predict using a classifer based on F1 score. '''\n",
        "    \n",
        "    # Indicate the classifier and the training set size\n",
        "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
        "    \n",
        "    # Train the classifier\n",
        "    train_classifier(clf, X_train, y_train)\n",
        "    \n",
        "    # Print the results of prediction for both training and testing\n",
        "    f1, acc = predict_labels(clf, X_train, y_train)\n",
        "    print(f1, acc)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "    \n",
        "    f1, acc = predict_labels(clf, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTf2qpgdMnMT",
        "colab_type": "code",
        "outputId": "272c3233-2da3-47d2-ddd3-586fada25d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Initialize the four models (XGBoost is initialized later)\n",
        "clf_A = LogisticRegression(random_state = 42)\n",
        "clf_B = KNeighborsClassifier(n_neighbors=10)\n",
        "clf_C = RandomForestClassifier(max_depth = 2, random_state=0)\n",
        "clf_D = SVC(random_state = 912, kernel='rbf')\n",
        "\n",
        "# Boosting refers to this general problem of producing a very accurate prediction rule \n",
        "# by combining rough and moderately inaccurate rules-of-thumb\n",
        "clf_E = xgb.XGBClassifier(seed = 2)\n",
        "\n",
        "train_predict(clf_A, X_train, y_train, X_test, y_test)\n",
        "print('')\n",
        "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
        "print('')\n",
        "train_predict(clf_C, X_train, y_train, X_test, y_test)\n",
        "print('')\n",
        "train_predict(clf_D, X_train, y_train, X_test, y_test)\n",
        "print('')\n",
        "train_predict(clf_E, X_train, y_train, X_test, y_test)\n",
        "print('')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training a LogisticRegression using a training set size of 800. . .\n",
            "Trained model in 0.0162 seconds\n",
            "Made predictions in 0.0009 seconds.\n",
            "0.9841269841269841 0.99625\n",
            "F1 score and accuracy score for training set: 0.9841 , 0.9962.\n",
            "Made predictions in 0.0006 seconds.\n",
            "F1 score and accuracy score for test set: 0.9787 , 0.9950.\n",
            "\n",
            "Training a KNeighborsClassifier using a training set size of 800. . .\n",
            "Trained model in 0.0026 seconds\n",
            "Made predictions in 0.0256 seconds.\n",
            "0.9347826086956522 0.985\n",
            "F1 score and accuracy score for training set: 0.9348 , 0.9850.\n",
            "Made predictions in 0.0072 seconds.\n",
            "F1 score and accuracy score for test set: 0.8837 , 0.9750.\n",
            "\n",
            "Training a RandomForestClassifier using a training set size of 800. . .\n",
            "Trained model in 0.1177 seconds\n",
            "Made predictions in 0.0106 seconds.\n",
            "0.43902439024390244 0.91375\n",
            "F1 score and accuracy score for training set: 0.4390 , 0.9137.\n",
            "Made predictions in 0.0079 seconds.\n",
            "F1 score and accuracy score for test set: 0.4516 , 0.9150.\n",
            "\n",
            "Training a SVC using a training set size of 800. . .\n",
            "Trained model in 0.0066 seconds\n",
            "Made predictions in 0.0029 seconds.\n",
            "0.9894736842105264 0.9975\n",
            "F1 score and accuracy score for training set: 0.9895 , 0.9975.\n",
            "Made predictions in 0.0013 seconds.\n",
            "F1 score and accuracy score for test set: 0.8837 , 0.9750.\n",
            "\n",
            "Training a XGBClassifier using a training set size of 800. . .\n",
            "Trained model in 0.9271 seconds\n",
            "Made predictions in 0.0022 seconds.\n",
            "1.0 1.0\n",
            "F1 score and accuracy score for training set: 1.0000 , 1.0000.\n",
            "Made predictions in 0.0010 seconds.\n",
            "F1 score and accuracy score for test set: 0.9130 , 0.9800.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPhC0VbDc9Qe",
        "colab_type": "text"
      },
      "source": [
        "### **Grid Search Cross Validation**\n",
        "\n",
        "We perform Grid Search CV, which is the process of performing hyper parameter tuning in order to determine the optimal values for a given model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb6BpyktYuRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import 'GridSearchCV' and 'make_scorer'\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def log_reg_gridsearch(X_train, y_train, X_test, y_test, nfolds):\n",
        "    paramsLogReg = {\n",
        "        'penalty' : ['l1', 'l2'],\n",
        "        'C': [0.001,.009,0.01,.09,1,5,10,25],\n",
        "        'solver' : ['liblinear'],\n",
        "        'max_iter' : [100, 1000,2500, 5000]\n",
        "    }\n",
        "\n",
        "    # Initialize the classifier\n",
        "    clf = LogisticRegression()\n",
        "\n",
        "    # Make an f1 scoring function using 'make_scorer'\n",
        "    f1_scorer = make_scorer(f1_score,pos_label=0)\n",
        "\n",
        "    # Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "    grid_search = GridSearchCV(\n",
        "                          clf, \n",
        "                          scoring = f1_scorer, \n",
        "                          param_grid=paramsLogReg,\n",
        "                          cv = nfolds\n",
        "                          )\n",
        "    # Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_search = grid_search.fit(X_train,y_train)\n",
        "\n",
        "    # Get the estimator\n",
        "    log_reg_best = grid_search.best_estimator_\n",
        "    #print(log_reg_best)\n",
        "\n",
        "    # Report the final F1 score for training and testing after parameter tuning\n",
        "    f1, acc = predict_labels(log_reg_best, X_train, y_train)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "        \n",
        "    f1, acc = predict_labels(log_reg_best, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "    return log_reg_best\n",
        "\n",
        "\n",
        "\n",
        "def knn_gridsearch(X_train, y_train, X_test, y_test, nfolds):\n",
        "    paramsKNN = { \n",
        "        'n_neighbors' : [3,5,11,19],\n",
        "        'weights' : ['uniform','distance'],\n",
        "        'metric' : ['euclidean', 'manhattan']\n",
        "    }\n",
        "\n",
        "    # Initialize the classifier\n",
        "    clf = KNeighborsClassifier()\n",
        "\n",
        "    # Make an f1 scoring function using 'make_scorer'\n",
        "    f1_scorer = make_scorer(f1_score,pos_label=0)\n",
        "\n",
        "    # Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "    grid_search = GridSearchCV(\n",
        "                          clf, \n",
        "                          scoring = f1_scorer, \n",
        "                          param_grid=paramsKNN,\n",
        "                          cv = nfolds\n",
        "                          )\n",
        "    # Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_search = grid_search.fit(X_train,y_train)\n",
        "\n",
        "    # Get the estimator\n",
        "    knn_best = grid_search.best_estimator_\n",
        "    #print(knn_best)\n",
        "\n",
        "    # Report the final F1 score for training and testing after parameter tuning\n",
        "    f1, acc = predict_labels(knn_best, X_train, y_train)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "        \n",
        "    f1, acc = predict_labels(knn_best, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "    return knn_best \n",
        "\n",
        "\n",
        "def random_forest_gridsearch(X_train, y_train, X_test, y_test, nfolds):\n",
        "    # Number of trees in random forest\n",
        "    # n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "    n_estimators = [50, 150, 250]\n",
        "    # Number of features to consider at every split\n",
        "    max_features = ['auto', 'sqrt']\n",
        "    # Maximum number of levels in tree\n",
        "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "    max_depth.append(None)\n",
        "    # Minimum number of samples required to split a node\n",
        "    min_samples_split = [2, 5, 10]\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    min_samples_leaf = [1, 2, 4]\n",
        "    # Method of selecting samples for training each tree\n",
        "    bootstrap = [True, False]\n",
        "    \n",
        "    paramsRandForest = {\n",
        "      'n_estimators': [50, 150, 250],\n",
        "      'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
        "      'min_samples_split': [2, 4, 6]\n",
        "    }\n",
        "\n",
        "    # Initialize the classifier\n",
        "    clf = RandomForestClassifier(random_state=1)\n",
        "\n",
        "    # Make an f1 scoring function using 'make_scorer'\n",
        "    f1_scorer = make_scorer(f1_score,pos_label=0)\n",
        "\n",
        "    # Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "    grid_search = GridSearchCV(\n",
        "                          clf, \n",
        "                          scoring = f1_scorer, \n",
        "                          param_grid=paramsRandForest,\n",
        "                          cv = nfolds\n",
        "                          )\n",
        "    # Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_search = grid_search.fit(X_train,y_train)\n",
        "\n",
        "    # Get the estimator\n",
        "    rand_forest_best = grid_search.best_estimator_\n",
        "    #print(rand_forest_best)\n",
        "\n",
        "    # Report the final F1 score for training and testing after parameter tuning\n",
        "    f1, acc = predict_labels(rand_forest_best, X_train, y_train)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "        \n",
        "    f1, acc = predict_labels(rand_forest_best, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "    return rand_forest_best    \n",
        "\n",
        "\n",
        "def svm_gridsearch(X_train, y_train, X_test, y_test, nfolds):\n",
        "    paramsSVM = {\n",
        "      'C': [0.1,1, 10, 100], \n",
        "      'gamma': [1,0.1,0.01,0.001],\n",
        "      'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "    }\n",
        "\n",
        "    # Initialize the classifier\n",
        "    clf = SVC()\n",
        "\n",
        "    # Make an f1 scoring function using 'make_scorer'\n",
        "    f1_scorer = make_scorer(f1_score,pos_label=0)\n",
        "\n",
        "    # Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "    grid_search = GridSearchCV(\n",
        "                          clf, \n",
        "                          scoring = f1_scorer, \n",
        "                          param_grid=paramsSVM,\n",
        "                          cv = nfolds\n",
        "                          )\n",
        "    # Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_search = grid_search.fit(X_train,y_train)\n",
        "\n",
        "    # Get the estimator\n",
        "    svm_best = grid_search.best_estimator_\n",
        "    #print(svm_best)\n",
        "\n",
        "    # Report the final F1 score for training and testing after parameter tuning\n",
        "    f1, acc = predict_labels(svm_best, X_train, y_train)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "        \n",
        "    f1, acc = predict_labels(svm_best, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "    return svm_best    \n",
        "\n",
        "\n",
        "def xg_boost_gridsearch(X_train, y_train, X_test, y_test, nfolds):\n",
        "    \"\"\"paramsXGB = {\n",
        "      'learning_rate' : [0.1, 0.01, 0.05],\n",
        "      'n_estimators' : range(60, 220, 40),\n",
        "      'max_depth': range (2, 10, 1),\n",
        "      'min_child_weight': [3],\n",
        "      'gamma':[0.4],\n",
        "      'subsample' : [0.8],\n",
        "      'colsample_bytree' : [0.8],\n",
        "      'scale_pos_weight' : [1],\n",
        "      'reg_alpha':[1e-5]\n",
        "    }\"\"\"\n",
        "    paramsXGB = {\n",
        "      'n_estimators': [50,100,150,250,300,400,500,1000],\n",
        "      'max_depth': [5,6,7,8,9,10],\n",
        "      'max_delta_step': [0,1,2,3,4,5,6,7,8,9,10],\n",
        "      'min_child_weight': [1,2,3,4,5],\n",
        "      'subsample': [0.5,0.6,0.7,0.8,0.9,1],\n",
        "      'colsample_bytree': [0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
        "      'colsample_bylevel': [0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
        "      'learning_rate': [0.002,0.005,0.007,0.008,0.01,0.05,0.07,0.1,0.25,0.5] \n",
        "    }\n",
        "\n",
        "    # Initialize the classifier\n",
        "    clf = xgb.XGBClassifier(seed=2)\n",
        "\n",
        "    # Make an f1 scoring function using 'make_scorer'\n",
        "    f1_scorer = make_scorer(f1_score,pos_label=0)\n",
        "\n",
        "    # Perform grid search on the classifier using the f1_scorer as the scoring method\n",
        "    grid_search = GridSearchCV(\n",
        "                          clf, \n",
        "                          scoring = f1_scorer, \n",
        "                          param_grid=paramsXGB,\n",
        "                          cv = nfolds\n",
        "                          )\n",
        "    # Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_search = grid_search.fit(X_train,y_train)\n",
        "\n",
        "    # Get the estimator\n",
        "    xgb_best = grid_search.best_estimator_\n",
        "    #print(xgb_best)\n",
        "\n",
        "    # Report the final F1 score for training and testing after parameter tuning\n",
        "    f1, acc = predict_labels(xgb_best, X_train, y_train)\n",
        "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "        \n",
        "    f1, acc = predict_labels(xgb_best, X_test, y_test)\n",
        "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
        "\n",
        "    return xgb_best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJSRfkVfUPk",
        "colab_type": "text"
      },
      "source": [
        "We perform Grid Search CV on the model that produced the highest accuracy to see if we can get optimized solution with tuned parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4-cgZX1l8QC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "58cf7b74-8a18-40a9-fbb1-dd68b554d7f7"
      },
      "source": [
        "log_reg_gridsearch(X_train, y_train, X_test, y_test, 10)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Made predictions in 0.0006 seconds.\n",
            "F1 score and accuracy score for training set: 0.9948 , 0.9988.\n",
            "Made predictions in 0.0006 seconds.\n",
            "F1 score and accuracy score for test set: 1.0000 , 1.0000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRgHP5UW3fv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "dcbb14ea-f174-415c-af39-a3a99811c05f"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "nfolds = 10\n",
        "\n",
        "#create a dictionary of the models\n",
        "log_reg_best = log_reg_gridsearch(X_train, y_train, X_test, y_test, nfolds)\n",
        "print('')\n",
        "knn_best = knn_gridsearch(X_train, y_train, X_test, y_test, nfolds)\n",
        "print('')\n",
        "rf_best = random_forest_gridsearch(X_train, y_train, X_test, y_test, nfolds)\n",
        "print('')\n",
        "svm_best = svm_gridsearch(X_train, y_train, X_test, y_test, nfolds)\n",
        "print('')\n",
        "xgb_best = xg_boost_gridsearch(X_train, y_train, X_test, y_test, nfolds)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Made predictions in 0.0005 seconds.\n",
            "F1 score and accuracy score for training set: 0.9948 , 0.9988.\n",
            "Made predictions in 0.0005 seconds.\n",
            "F1 score and accuracy score for test set: 1.0000 , 1.0000.\n",
            "\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='distance')\n",
            "Made predictions in 0.0090 seconds.\n",
            "F1 score and accuracy score for training set: 1.0000 , 1.0000.\n",
            "Made predictions in 0.0030 seconds.\n",
            "F1 score and accuracy score for test set: 0.8182 , 0.9600.\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features=1.0,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=6,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
            "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
            "                       warm_start=False)\n",
            "Made predictions in 0.0144 seconds.\n",
            "F1 score and accuracy score for training set: 1.0000 , 1.0000.\n",
            "Made predictions in 0.0112 seconds.\n",
            "F1 score and accuracy score for test set: 0.9130 , 0.9800.\n",
            "\n",
            "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "Made predictions in 0.0021 seconds.\n",
            "F1 score and accuracy score for training set: 1.0000 , 1.0000.\n",
            "Made predictions in 0.0010 seconds.\n",
            "F1 score and accuracy score for test set: 0.9565 , 0.9900.\n",
            "\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=3, missing=None, n_estimators=40, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, seed=2,\n",
            "              silent=None, subsample=0.8, verbosity=1)\n",
            "Made predictions in 0.0012 seconds.\n",
            "F1 score and accuracy score for training set: 0.9681 , 0.9925.\n",
            "Made predictions in 0.0008 seconds.\n",
            "F1 score and accuracy score for test set: 0.8095 , 0.9600.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAgQsgSg47DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a dictionary of our models\n",
        "estimators = [('log_reg', log_reg_best),('knn', knn_best), ('rf', rf_best), ('svm', svm_best)]\n",
        "\n",
        "#create our voting classifier, inputting our models\n",
        "ensemble = VotingClassifier(estimators, voting='hard')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYbt1vHh4TKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d189278-1392-4491-dd94-4a202b5628d3"
      },
      "source": [
        "#fit model to training data\n",
        "ensemble.fit(X_train, y_train)\n",
        "#test our model on the test data\n",
        "ensemble.score(X_test, y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}